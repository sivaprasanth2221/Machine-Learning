{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4bde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e151fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature = feature          \n",
    "        self.threshold = threshold      \n",
    "        self.value = value              \n",
    "        self.true_branch = true_branch  \n",
    "        self.false_branch = false_branch  \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth      \n",
    "        self.root = None                \n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        \n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return Node(value=np.bincount(y).argmax())\n",
    "\n",
    "        num_samples, num_features = X.shape\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                y_true = y[X[:, feature] <= threshold]\n",
    "                y_false = y[X[:, feature] > threshold]\n",
    "\n",
    "                if len(y_true) == 0 or len(y_false) == 0:\n",
    "                    continue\n",
    "\n",
    "                gini = self.calculate_gini(y_true, y_false)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        if best_feature is None:\n",
    "            return Node(value=np.bincount(y).argmax())\n",
    "\n",
    "        true_indices = X[:, best_feature] <= best_threshold\n",
    "        false_indices = ~true_indices\n",
    "\n",
    "        true_branch = self.fit(X[true_indices], y[true_indices], depth + 1)\n",
    "        false_branch = self.fit(X[false_indices], y[false_indices], depth + 1)\n",
    "\n",
    "        return Node(best_feature, best_threshold, true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    def calculate_gini(self, y_true, y_false):\n",
    "        gini_true = 1.0 - sum((np.bincount(y_true) / len(y_true)) ** 2)\n",
    "        gini_false = 1.0 - sum((np.bincount(y_false) / len(y_false)) ** 2)\n",
    "        weighted_gini = (len(y_true) * gini_true + len(y_false) * gini_false) / (len(y_true) + len(y_false))\n",
    "        return weighted_gini\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x, self.root) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._predict(x, node.true_branch)\n",
    "        else:\n",
    "            return self._predict(x, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0f23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/rh2g9yxd7g3cyb4mfg9369j80000gn/T/ipykernel_1715/2478000851.py:5: RuntimeWarning: invalid value encountered in cast\n",
      "  y = data[:, -1].astype(int)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('Date_Fruit_Datasets.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017921a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(max_depth=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "dt.root = dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19371d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fd15dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       180\n",
      "   macro avg       1.00      1.00      1.00       180\n",
      "weighted avg       1.00      1.00      1.00       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8d8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d52c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08679706601466992\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"Date_Fruit_Datasets.csv\")\n",
    "\n",
    "# Define a class to represent a node in the Decision Tree\n",
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, result=None):\n",
    "        self.feature, self.value, self.result = feature, value, result\n",
    "        self.left, self.right = None, None\n",
    "\n",
    "# Calculate Gini Impurity\n",
    "def gini_impurity(labels):\n",
    "    total = len(labels)\n",
    "    return 1.0 - sum((labels.value_counts() / total) ** 2)\n",
    "\n",
    "# Split dataset based on a feature and value\n",
    "def split_dataset(X, y, feature, value):\n",
    "    return X[X[feature] <= value], y[X[feature] <= value], X[X[feature] > value], y[X[feature] > value]\n",
    "\n",
    "# Build the Decision Tree recursively\n",
    "def build_tree(X, y, depth=0, max_depth=None):\n",
    "    if len(set(y)) == 1:\n",
    "        return Node(result=y.iloc[0])\n",
    "    if len(y) == 0:\n",
    "        return Node(result=y.value_counts().idxmax())\n",
    "    if max_depth is not None and depth >= max_depth:\n",
    "        return Node(result=y.value_counts().idxmax())\n",
    "    \n",
    "    best_gini, best_feature, best_value, left_X, left_y, right_X, right_y = 1.0, None, None, None, None, None, None\n",
    "    \n",
    "    for feature in X.columns:\n",
    "        for value in X[feature].unique():\n",
    "            l_X, l_y, r_X, r_y = split_dataset(X, y, feature, value)\n",
    "            impurity = (len(l_y) * gini_impurity(l_y) + len(r_y) * gini_impurity(r_y)) / len(y)\n",
    "            if impurity < best_gini:\n",
    "                best_gini, best_feature, best_value, left_X, left_y, right_X, right_y = impurity, feature, value, l_X, l_y, r_X, r_y\n",
    "    \n",
    "    if best_gini == 1.0:\n",
    "        return Node(result=y.value_counts().idxmax())\n",
    "    \n",
    "    node = Node(feature=best_feature, value=best_value)\n",
    "    node.left = build_tree(left_X, left_y, depth + 1, max_depth)\n",
    "    node.right = build_tree(right_X, right_y, depth + 1, max_depth)\n",
    "    return node\n",
    "\n",
    "# Make predictions using the Decision Tree\n",
    "def predict_tree(node, sample):\n",
    "    if node.result is not None:\n",
    "        return node.result\n",
    "    return predict_tree(node.left, sample) if sample[node.feature] <= node.value else predict_tree(node.right, sample)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, y_train = df.iloc[:80, :-1], df.iloc[:80, -1]\n",
    "X_test, y_test = df.iloc[80:, :-1], df.iloc[80:, -1]\n",
    "\n",
    "# Build the Decision Tree with a maximum depth of 5\n",
    "tree = build_tree(X_train, y_train, max_depth=5)\n",
    "\n",
    "# Make predictions for test data\n",
    "y_pred = [predict_tree(tree, sample) for _, sample in X_test.iterrows()]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2597407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
